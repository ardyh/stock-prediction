{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/analysis/stock_data.json\")\n",
    "df_batch = pd.read_json(\"data/analysis/batch_data.json\")\n",
    "df_train = pd.read_json(\"data/analysis/stock_data_train.json\")\n",
    "df_test = pd.read_json(\"data/analysis/stock_data_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_batch</th>\n",
       "      <th>main_mv_percent_batch</th>\n",
       "      <th>word_batch</th>\n",
       "      <th>n_msgs_batch</th>\n",
       "      <th>T_batch</th>\n",
       "      <th>main_target_date_batch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>price_batch</th>\n",
       "      <th>texts_batch</th>\n",
       "      <th>stock_batch</th>\n",
       "      <th>s</th>\n",
       "      <th>n_words_batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0....</td>\n",
       "      <td>[-0.005330999847501, 0.006130000110715001, 0.0...</td>\n",
       "      <td>[[[[18764, 25572, 4165, 26136, 16603, 322, 247...</td>\n",
       "      <td>[[12, 2, 1, 4, 0], [20, 2, 1, 0, 0], [3, 20, 2...</td>\n",
       "      <td>[4, 3, 3, 3, 5, 4, 3, 3, 5, 4, 3, 2, 3, 3, 4, ...</td>\n",
       "      <td>[2015-07-30, 2015-07-29, 2015-07-28, 2015-07-2...</td>\n",
       "      <td>135</td>\n",
       "      <td>[[[0.06799300014972601, 0.04161800071597, -0.4...</td>\n",
       "      <td>[[[['unh', 'unitedhealth', 'group', ',', 'inc'...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>GE</td>\n",
       "      <td>[[[20, 21, 27, 23, 18, 19, 19, 22, 19, 18, 27,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             y_batch  \\\n",
       "0  [[[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0....   \n",
       "\n",
       "                               main_mv_percent_batch  \\\n",
       "0  [-0.005330999847501, 0.006130000110715001, 0.0...   \n",
       "\n",
       "                                          word_batch  \\\n",
       "0  [[[[18764, 25572, 4165, 26136, 16603, 322, 247...   \n",
       "\n",
       "                                        n_msgs_batch  \\\n",
       "0  [[12, 2, 1, 4, 0], [20, 2, 1, 0, 0], [3, 20, 2...   \n",
       "\n",
       "                                             T_batch  \\\n",
       "0  [4, 3, 3, 3, 5, 4, 3, 3, 5, 4, 3, 2, 3, 3, 4, ...   \n",
       "\n",
       "                              main_target_date_batch  batch_size  \\\n",
       "0  [2015-07-30, 2015-07-29, 2015-07-28, 2015-07-2...         135   \n",
       "\n",
       "                                         price_batch  \\\n",
       "0  [[[0.06799300014972601, 0.04161800071597, -0.4...   \n",
       "\n",
       "                                         texts_batch  \\\n",
       "0  [[[['unh', 'unitedhealth', 'group', ',', 'inc'...   \n",
       "\n",
       "                                         stock_batch   s  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  GE   \n",
       "\n",
       "                                       n_words_batch  \n",
       "0  [[[20, 21, 27, 23, 18, 19, 19, 22, 19, 18, 27,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data: Price & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       GE\n",
       "9      JPM\n",
       "11     BAC\n",
       "13       C\n",
       "19       D\n",
       "26    AAPL\n",
       "44    GOOG\n",
       "45    MSFT\n",
       "46      FB\n",
       "47       T\n",
       "52    INTC\n",
       "63    CELG\n",
       "64    AMZN\n",
       "73    PCLN\n",
       "Name: s, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only stocks with batch_size > 120\n",
    "# We take arbitrary number 120\n",
    "B = 120\n",
    "sel_stocks = df_train[df_train.batch_size > 120]\n",
    "sel_stocks.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4614065180102916, 0.5385934819897085)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: check the ratio of up and down labels\n",
    "# Get y_batch from sel_stocks and count number of [1,0] and [0,1] labels\n",
    "y_counts = {'up': 0, 'down': 0}\n",
    "for y_batch in sel_stocks.y_batch:\n",
    "    y_arr = np.array(y_batch)\n",
    "    y_counts['up'] += np.sum(np.all(y_arr == [1,0], axis=1))\n",
    "    y_counts['down'] += np.sum(np.all(y_arr == [0,1], axis=1))\n",
    "\n",
    "# find ratio of up and down\n",
    "ratio = y_counts['up'] / (y_counts['up'] + y_counts['down'])\n",
    "ratio, 1-ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = False\n",
    "if OUT:\n",
    "    # Fetch price_batch from sel_stocks and limit them to 100 batches per stock\n",
    "    price_batches = []\n",
    "    for price_batch in sel_stocks.price_batch:\n",
    "        price_batches.append(price_batch[:120])\n",
    "    price_batches = np.array(price_batches)\n",
    "    # Save 120 .npy files of (14, 5, 3) dim numpy arrays\n",
    "    for i in range(price_batches.shape[1]):\n",
    "        np.save(f\"data/out/train_price/{str(i).zfill(10)}.npy\", price_batches[:, i, :])\n",
    "\n",
    "    # Fetch y_batch from sel_stocks and limit them to 100 batches per stock\n",
    "    y_batches = []\n",
    "    for y_batch in sel_stocks.y_batch:\n",
    "        y_batches.append(y_batch[:120])\n",
    "    y_batches = np.array(y_batches)\n",
    "    # Save 120 .npy files of (14, 5, 2) dim numpy arrays\n",
    "    for i in range(y_batches.shape[1]):\n",
    "        np.save(f\"data/out/train_label/{str(i).zfill(10)}.npy\", y_batches[:, i, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy newly generated data to man_sf_emnlp repo\n",
    "!cp -r data/out/train_label/ ../man-sf-emnlp/train_label/\n",
    "!cp -r data/out/train_price/ ../man-sf-emnlp/train_price/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data: Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Universal Sentence Encoder model...\n"
     ]
    }
   ],
   "source": [
    "# Get texts_batch from sel_stocks and convert to embeddings\n",
    "print(\"Loading Universal Sentence Encoder model...\")\n",
    "embed = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (120, 14, 5, 30, 512)\n"
     ]
    }
   ],
   "source": [
    "# Process each batch of texts\n",
    "# Numpy array to store all embeddings\n",
    "\n",
    "debug = True\n",
    "max_tweets = 30  # Max tweets per day\n",
    "n_window = 5     # Days window\n",
    "emb_size = 512   # Embedding dimension\n",
    "padding = np.zeros(emb_size)  # Use numpy zeros for padding\n",
    "\n",
    "num_stocks = len(sel_stocks)\n",
    "B = 120  # Number of batches\n",
    "\n",
    "# Initialize output array with zeros\n",
    "all_embeddings = np.zeros((B, num_stocks, n_window, max_tweets, emb_size))\n",
    "\n",
    "# Process each stock\n",
    "for stock_idx, texts_batch in enumerate(sel_stocks.texts_batch):\n",
    "    # Process each batch\n",
    "    for batch_idx, batch in enumerate(texts_batch[:B]):\n",
    "        # Process each day window\n",
    "        for day_idx, days in enumerate(batch[:n_window]):\n",
    "            # Process tweets for this day\n",
    "            day_tweets = []\n",
    "            for tweets in days:\n",
    "                for tweet in tweets:\n",
    "                    # Join words into single string, filtering out empty strings\n",
    "                    tweet_text = ' '.join([w for w in tweet if w])\n",
    "                    tweet_vec = embed([tweet_text])[0].numpy()\n",
    "                    day_tweets.append(tweet_vec)\n",
    "\n",
    "            # Pad or truncate tweets for this day\n",
    "            if len(day_tweets) > 0:\n",
    "                day_tweets = np.array(day_tweets[:max_tweets])\n",
    "                if len(day_tweets) < max_tweets:\n",
    "                    padding_needed = max_tweets - len(day_tweets)\n",
    "                    padding_array = np.zeros((padding_needed, emb_size))\n",
    "                    day_tweets = np.vstack([day_tweets, padding_array])\n",
    "            else:\n",
    "                day_tweets = np.zeros((max_tweets, emb_size))\n",
    "                \n",
    "            # Store in final array\n",
    "            all_embeddings[batch_idx, stock_idx, day_idx] = day_tweets\n",
    "\n",
    "    if debug and stock_idx == 0:\n",
    "        break\n",
    "\n",
    "print(f\"Final shape: {all_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(all_embeddings.shape[0]):\n",
    "    np.save(f\"data/out/train_text/{str(i).zfill(10)}.npy\", all_embeddings[i, :, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5, 30, 512)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the embedding shapes\n",
    "print(np.load(f\"../man-sf-emnlp/train_text/{str(1).zfill(10)}.npy\").shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy newly generated data to man-sf-emnlp repo\n",
    "!cp -r data/out/train_text/ ../man-sf-emnlp/train_text/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Testing Data: Price & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_test y_batch and price_batch as pickle files based on date\n",
    "\n",
    "# Select only stocks in df_test that are in df_train.s \n",
    "sel_stocks_test = df_test[df_test.s.isin(sel_stocks.s)].set_index('s')\n",
    "test_batch_size = sel_stocks_test.batch_size.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.array(sel_stocks_test.y_batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = True\n",
    "if OUT:\n",
    "    # Fetch price_batch from sel_stocks_test and limit them to 100 batches per stock\n",
    "    price_batches = []\n",
    "    for price_batch in sel_stocks_test.price_batch:\n",
    "        price_batches.append(price_batch[:test_batch_size])\n",
    "    price_batches = np.array(price_batches)\n",
    "    \n",
    "    # Create dictionary to store price data\n",
    "    price_dict = {}\n",
    "    for i in range(price_batches.shape[1]):\n",
    "        key = str(i).zfill(10)\n",
    "        price_dict[key] = price_batches[:, i, :]\n",
    "    \n",
    "    # Save price dictionary\n",
    "    with open('data/out/price_feature_data.p', 'wb') as f:\n",
    "        pickle.dump(price_dict, f)\n",
    "\n",
    "    # Fetch y_batch from sel_stocks_test and limit them to 100 batches per stock\n",
    "    y_batches = []\n",
    "    for y_batch in sel_stocks_test.y_batch:\n",
    "        y_batches.append(y_batch[:test_batch_size])\n",
    "    y_batches = np.array(y_batches)\n",
    "    \n",
    "    # Create dictionary to store label data\n",
    "    label_dict = {}\n",
    "    \n",
    "    # Original shape:(num_stocks, test_batch_size, 5, 2)\n",
    "    for batch_idx in range(y_batches.shape[1]):\n",
    "        batch_labels = []\n",
    "        for stock_idx in range(y_batches.shape[0]):\n",
    "            # Get the 5-day window for current stock and batch\n",
    "            window = y_batches[stock_idx, batch_idx]\n",
    "            # Find rows where one-hot encoding sums to 1 (valid labels)\n",
    "            nonzero_rows = (window.sum(axis=1) == 1.0).nonzero()[0]\n",
    "            if len(nonzero_rows) > 0:\n",
    "                # Get last valid label in window\n",
    "                last_effective_idx = nonzero_rows[-1]\n",
    "                last_effective_label = window[last_effective_idx]\n",
    "                batch_labels.append(last_effective_label)\n",
    "        # Store labels for this batch in dictionary\n",
    "        batch_labels = np.array(batch_labels)  # Shape: (num_stocks, 2)\n",
    "        key = str(batch_idx).zfill(10)\n",
    "        label_dict[key] = batch_labels\n",
    "    \n",
    "    # Save label dictionary\n",
    "    with open('data/out/label_data.p', 'wb') as f:\n",
    "        pickle.dump(label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5, 3)\n",
      "(14, 2)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the pickle data\n",
    "with open('data/out/price_feature_data.p', 'rb') as f:\n",
    "    price_dict = pickle.load(f)\n",
    "print(price_dict['0000000001'].shape)\n",
    "\n",
    "with open('data/out/label_data.p', 'rb') as f:\n",
    "    label_dict = pickle.load(f)\n",
    "print(label_dict['0000000001'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy newly generated data to man_sf_emnlp repo\n",
    "!cp -r data/out/label_data.p ../man-sf-emnlp/label_data.p\n",
    "!cp -r data/out/price_feature_data.p ../man-sf-emnlp/price_feature_data.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Testing Data: Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Universal Sentence Encoder model...\n"
     ]
    }
   ],
   "source": [
    "# Get texts_batch from sel_stocks and convert to embeddings\n",
    "print(\"Loading Universal Sentence Encoder model...\")\n",
    "embed = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (20, 14, 5, 30, 512)\n"
     ]
    }
   ],
   "source": [
    "# Process each batch of texts\n",
    "# Numpy array to store all embeddings\n",
    "\n",
    "debug = True\n",
    "max_tweets = 30  # Max tweets per day\n",
    "n_window = 5     # Days window\n",
    "emb_size = 512   # Embedding dimension\n",
    "padding = np.zeros(emb_size)  # Use numpy zeros for padding\n",
    "\n",
    "num_stocks = len(sel_stocks_test)\n",
    "B = test_batch_size  # Number of batches\n",
    "\n",
    "# Initialize output array with zeros\n",
    "all_embeddings = np.zeros((B, num_stocks, n_window, max_tweets, emb_size))\n",
    "\n",
    "# Process each stock\n",
    "for stock_idx, texts_batch in enumerate(sel_stocks_test.texts_batch):\n",
    "    # Process each batch\n",
    "    for batch_idx, batch in enumerate(texts_batch[:B]):\n",
    "        # Process each day window\n",
    "        for day_idx, days in enumerate(batch[:n_window]):\n",
    "            # Process tweets for this day\n",
    "            day_tweets = []\n",
    "            for tweets in days:\n",
    "                for tweet in tweets:\n",
    "                    # Join words into single string, filtering out empty strings\n",
    "                    tweet_text = ' '.join([w for w in tweet if w])\n",
    "                    tweet_vec = embed([tweet_text])[0].numpy()\n",
    "                    day_tweets.append(tweet_vec)\n",
    "\n",
    "            # Pad or truncate tweets for this day\n",
    "            if len(day_tweets) > 0:\n",
    "                day_tweets = np.array(day_tweets[:max_tweets])\n",
    "                if len(day_tweets) < max_tweets:\n",
    "                    padding_needed = max_tweets - len(day_tweets)\n",
    "                    padding_array = np.zeros((padding_needed, emb_size))\n",
    "                    day_tweets = np.vstack([day_tweets, padding_array])\n",
    "            else:\n",
    "                day_tweets = np.zeros((max_tweets, emb_size))\n",
    "                \n",
    "            # Store in final array\n",
    "            all_embeddings[batch_idx, stock_idx, day_idx] = day_tweets\n",
    "\n",
    "    if debug and stock_idx == 0:\n",
    "        break\n",
    "\n",
    "print(f\"Final shape: {all_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store embeddings\n",
    "embeddings_dict = {}\n",
    "for i in range(all_embeddings.shape[0]):\n",
    "    embeddings_dict[str(i).zfill(10)] = all_embeddings[i, :, :, :, :]\n",
    "\n",
    "# Save dictionary as pickle file\n",
    "with open('data/out/text_feature_data.p', 'wb') as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5, 30, 512)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the embedding shapes\n",
    "with open('data/out/text_feature_data.p', 'rb') as f:\n",
    "    embeddings_dict = pickle.load(f)\n",
    "print(embeddings_dict['0000000001'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy newly generated data to man-sf-emnlp repo\n",
    "!cp -r data/out/text_feature_data.p ../man-sf-emnlp/text_feature_data.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]),\n",
       " '\\n',\n",
       " array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train_label from data/out/train_label\n",
    "train_label = np.load(\"data/out/train_label/0000000001.npy\")\n",
    "\n",
    "# df_train[['y_batch', 'price_batch']].head(1).values\n",
    "torch.max(torch.LongTensor(train_label), 1)[1], '\\n', train_label\n",
    "# train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Read all files within data/out/train_label/ and rewrite each file \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get all files in train_label_v1 directory\n",
    "label_files = sorted(os.listdir(\"data/out/train_label_v1/\"))\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"data/out/train_label/\", exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for filename in label_files:\n",
    "    # Load label file\n",
    "    train_label = np.load(f\"data/out/train_label_v1/{filename}\")\n",
    "    \n",
    "    # Extract last effective label for each sequence\n",
    "    labels = []\n",
    "    for i in range(train_label.shape[0]):\n",
    "        nonzero_rows = (train_label[i].sum(axis=1) == 1.0).nonzero()[0]\n",
    "        if len(nonzero_rows) > 0:\n",
    "            last_effective_idx = nonzero_rows[-1]\n",
    "            last_effective_label = train_label[i, last_effective_idx]\n",
    "            labels.append(last_effective_label)\n",
    "        \n",
    "    # Save processed labels\n",
    "    labels = np.array(labels)\n",
    "    np.save(f\"data/out/train_label/{filename}\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.067993,  0.041618, -0.478625],\n",
       "       [ 0.075076,  0.056041,  0.187695],\n",
       "       [ 0.077466,  0.065559,  0.140772],\n",
       "       [ 0.      ,  0.      ,  0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read train_price from data/out/train_price\n",
    "train_price = np.load(\"data/out/train_price/0000000001.npy\")\n",
    "train_price[0]\n",
    "# df_train[['price_batch']].head(1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = np.load(\"data/out/train_label_v1/0000000001.npy\")\n",
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_batch</th>\n",
       "      <th>main_mv_percent_batch</th>\n",
       "      <th>word_batch</th>\n",
       "      <th>n_msgs_batch</th>\n",
       "      <th>T_batch</th>\n",
       "      <th>main_target_date_batch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>price_batch</th>\n",
       "      <th>texts_batch</th>\n",
       "      <th>stock_batch</th>\n",
       "      <th>s</th>\n",
       "      <th>n_words_batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 0....</td>\n",
       "      <td>[-0.007352999877184001, 0.012298000045120001, ...</td>\n",
       "      <td>[[[[20239, 22919, 26136, 16603, 322, 2804, 819...</td>\n",
       "      <td>[[4, 2, 5, 0, 0], [8, 2, 0, 0, 0], [1, 4, 2, 0...</td>\n",
       "      <td>[3, 2, 3, 2, 3, 4, 3, 4, 3, 3, 3, 5, 3, 3, 4, ...</td>\n",
       "      <td>[2015-12-30, 2015-12-29, 2015-12-23, 2015-11-3...</td>\n",
       "      <td>178</td>\n",
       "      <td>[[[0.047589000314474, 0.039459999650716004, -0...</td>\n",
       "      <td>[[[['aa', 'alcoa', ',', 'inc', '.', 'ask', 'UR...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>GE</td>\n",
       "      <td>[[[18, 18, 26, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             y_batch  \\\n",
       "0  [[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 0....   \n",
       "\n",
       "                               main_mv_percent_batch  \\\n",
       "0  [-0.007352999877184001, 0.012298000045120001, ...   \n",
       "\n",
       "                                          word_batch  \\\n",
       "0  [[[[20239, 22919, 26136, 16603, 322, 2804, 819...   \n",
       "\n",
       "                                        n_msgs_batch  \\\n",
       "0  [[4, 2, 5, 0, 0], [8, 2, 0, 0, 0], [1, 4, 2, 0...   \n",
       "\n",
       "                                             T_batch  \\\n",
       "0  [3, 2, 3, 2, 3, 4, 3, 4, 3, 3, 3, 5, 3, 3, 4, ...   \n",
       "\n",
       "                              main_target_date_batch  batch_size  \\\n",
       "0  [2015-12-30, 2015-12-29, 2015-12-23, 2015-11-3...         178   \n",
       "\n",
       "                                         price_batch  \\\n",
       "0  [[[0.047589000314474, 0.039459999650716004, -0...   \n",
       "\n",
       "                                         texts_batch  \\\n",
       "0  [[[['aa', 'alcoa', ',', 'inc', '.', 'ask', 'UR...   \n",
       "\n",
       "                                         stock_batch   s  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  GE   \n",
       "\n",
       "                                       n_words_batch  \n",
       "0  [[[18, 18, 26, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexp = pd.read_json(\"data/analysis/stock_data_v2.json\")\n",
    "dfexp.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 7, 14, 1901, 3802, 13307, 26614]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_factors(n):\n",
    "    return [i for i in range(1, n+1) if n % i == 0]\n",
    "find_factors(26614)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74, 11), (58, 11), (75, 11))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4987, 1008, 6651)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.batch_size.sum(), df_test.batch_size.sum(), df.batch_size.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(df.y_batch[0]).shape\n",
    "shapes = []\n",
    "df.y_batch.apply(lambda x: shapes.append(np.array(x).shape))\n",
    "pd.Series(shapes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5      3\n",
       " 2      3\n",
       " 93     2\n",
       " 3      2\n",
       " 15     2\n",
       "       ..\n",
       " 43     1\n",
       " 156    1\n",
       " 123    1\n",
       " 64     1\n",
       " 218    1\n",
       " Name: count, Length: 61, dtype: int64,\n",
       " 6651)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsample_per_stock = []\n",
    "df.y_batch.apply(lambda x: nsample_per_stock.append(len(np.array(x))))\n",
    "pd.Series(nsample_per_stock).value_counts(), sum(nsample_per_stock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndatapoint_per_stock = []\n",
    "df.y_batch.apply(lambda x: ndatapoint_per_stock.append(\n",
    "        np.array(x).shape[0] * np.array(x).shape[1]\n",
    "    )\n",
    ")\n",
    "sum(ndatapoint_per_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.n_words_batch.apply(lambda x: np.array(x))[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2029\n",
       "4     515\n",
       "2     374\n",
       "5     282\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The column T_batch is a list of lists, each sublist is a list of days\n",
    "# Find the number of unique days in T_batch\n",
    "days = []\n",
    "df_batch.T_batch.apply(lambda x: days.extend(x))\n",
    "pd.Series(days).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_batch</th>\n",
       "      <th>word_batch</th>\n",
       "      <th>main_mv_percent_batch</th>\n",
       "      <th>n_msgs_batch</th>\n",
       "      <th>n_words_batch</th>\n",
       "      <th>y_batch</th>\n",
       "      <th>stock_batch</th>\n",
       "      <th>price_batch</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 3, 2, 5, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 2, ...</td>\n",
       "      <td>[[[[6833, 12221, 22879, 22971, 22030, 25982, 2...</td>\n",
       "      <td>[0.012745999731123002, 0.006849000230431001, -...</td>\n",
       "      <td>[[2, 6, 1, 4, 0], [1, 2, 1, 0, 0], [1, 2, 0, 0...</td>\n",
       "      <td>[[[28, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1....</td>\n",
       "      <td>[59, 29, 8, 80, 71, 82, 56, 53, 52, 64, 66, 78...</td>\n",
       "      <td>[[[0.06393899768590901, 0.051995001733303, -0....</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             T_batch  \\\n",
       "0  [4, 3, 2, 5, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 2, ...   \n",
       "\n",
       "                                          word_batch  \\\n",
       "0  [[[[6833, 12221, 22879, 22971, 22030, 25982, 2...   \n",
       "\n",
       "                               main_mv_percent_batch  \\\n",
       "0  [0.012745999731123002, 0.006849000230431001, -...   \n",
       "\n",
       "                                        n_msgs_batch  \\\n",
       "0  [[2, 6, 1, 4, 0], [1, 2, 1, 0, 0], [1, 2, 0, 0...   \n",
       "\n",
       "                                       n_words_batch  \\\n",
       "0  [[[28, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                             y_batch  \\\n",
       "0  [[[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1....   \n",
       "\n",
       "                                         stock_batch  \\\n",
       "0  [59, 29, 8, 80, 71, 82, 56, 53, 52, 64, 66, 78...   \n",
       "\n",
       "                                         price_batch  batch_size  \n",
       "0  [[[0.06393899768590901, 0.051995001733303, -0....          32  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batch.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocknet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
